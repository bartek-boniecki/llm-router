services:
  
  api:
    build:
      context: .
      dockerfile: ./docker/Dockerfile
    env_file: .env
    environment:
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      ANTHROPIC_API_KEY: ${ANTHROPIC_API_KEY}
      GEMINI_API_KEY: ${GEMINI_API_KEY}
      MISTRAL_API_KEY: ${MISTRAL_API_KEY}
      PRICE_TABLE_PATH: ${PRICE_TABLE_PATH}
      RATE_LIMIT_ENABLED: ${RATE_LIMIT_ENABLED}
      RABBITMQ_URL: ${RABBITMQ_URL}
      OLLAMA_BASE_URL: ${OLLAMA_BASE_URL}
      GOOGLE_OAUTH_PORT: 8765
      PIPEDRIVE_API_TOKEN: ${PIPEDRIVE_API_TOKEN}
      PIPEDRIVE_BASE_URL: ${PIPEDRIVE_BASE_URL}
      # (Optional) Tunables we added earlier for resilience
      OLLAMA_READ_TIMEOUT_S: ${OLLAMA_READ_TIMEOUT_S:-600}
      OLLAMA_CONNECT_TIMEOUT_S: ${OLLAMA_CONNECT_TIMEOUT_S:-10}
      OLLAMA_WRITE_TIMEOUT_S: ${OLLAMA_WRITE_TIMEOUT_S:-30}
      OLLAMA_RETRIES: ${OLLAMA_RETRIES:-2}
      OLLAMA_RETRY_BACKOFF_S: ${OLLAMA_RETRY_BACKOFF_S:-5.0}
      TRIAGE_DEFAULT_N: ${TRIAGE_DEFAULT_N:-3}
      TRIAGE_LOOKBACK_DAYS: ${TRIAGE_LOOKBACK_DAYS:-30}
      TRIAGE_MAX_CONTEXT_CHARS: ${TRIAGE_MAX_CONTEXT_CHARS:-4000}
      MODEL_TRIAGE_PRIMARY: ${MODEL_TRIAGE_PRIMARY:-phi3:mini}
      MODEL_TRIAGE_FALLBACK: ${MODEL_TRIAGE_FALLBACK:-tinyllama}
    ports:
      - "8000:8000"     # FastAPI
      - "8765:8765"     # Google OAuth callback (primary)
      - "8780:8780"     # Google OAuth callback (fallback 1)
      - "8790:8790"     # Google OAuth callback (fallback 2)
    volumes:
      - ./:/app
      - ./secrets:/app/secrets   # persist Google & MS token caches to host
      - ./scripts:/app/scripts   
      - ./state:/app/state
    depends_on:
      db:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
      # only require that the container has started; healthcheck no longer blocks API start
      ollama:
        condition: service_started
    restart: unless-stopped

  worker:
    build:
      context: .
      dockerfile: ./docker/Dockerfile
    command: ["python", "-m", "app.queue_worker"]
    env_file: .env
    environment:
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      ANTHROPIC_API_KEY: ${ANTHROPIC_API_KEY}
      GEMINI_API_KEY: ${GEMINI_API_KEY}
      MISTRAL_API_KEY: ${MISTRAL_API_KEY}
      PRICE_TABLE_PATH: ${PRICE_TABLE_PATH}
      RATE_LIMIT_ENABLED: ${RATE_LIMIT_ENABLED}
      RABBITMQ_URL: ${RABBITMQ_URL}
      OLLAMA_BASE_URL: ${OLLAMA_BASE_URL}
    volumes:
      - ./secrets:/app/secrets   # ← optional but handy if worker ever needs MS token
    depends_on:
      db:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
      ollama:
        condition: service_started
    restart: unless-stopped

  db:
    image: postgres:15
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: router
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 5s
      retries: 5
    restart: unless-stopped

  rabbitmq:
    image: rabbitmq:3-management
    environment:
      RABBITMQ_DEFAULT_USER: router
      RABBITMQ_DEFAULT_PASS: routerpass
    ports:
      - "5672:5672"
      - "15672:15672"
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "-q", "ping"]
      interval: 5s
      retries: 10
    restart: unless-stopped

  # Local LLM runtime
  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    healthcheck:
      test: ["CMD-SHELL", "ollama list >/dev/null 2>&1 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 30
      start_period: 20s
    volumes:
      - ollama:/root/.ollama
    restart: unless-stopped

  minio:
    image: minio/minio:latest
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    ports:
      - "9000:9000"
      - "9001:9001"
    restart: unless-stopped

volumes:
  ollama:
